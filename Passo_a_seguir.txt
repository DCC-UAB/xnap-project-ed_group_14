Coses que hem fet:l
- Dividim el train i test en 80% i 20%
- Creem el dataloader a partir de el dataset
- Hem utilizat la loss --> que es la crossentropy
- WandB, que el que fem 8 per el train, 4 que son per veure com anem entrenant i 4 per veure un exemple de validacio per veure si estem fent overfitting o no.
- Per guardar el millor model hem fet un set de validacio, per cada epoch
- Hem creat el test perque no hi havia, el que fem en el test és anar imatge per imatge predint.
- Metriques:
    - Coefficient de Jaccard:
        - Eliminem totes les coses que no siguin paraules, excepte si no es coneix.
        - Per veure el model fem una divisio entre les paraules que concordden entre totes.
            - Aquesta metrica nomes mira si estan les paraules sense tenir en compte cap ordre.
    - Bleu Score:
        - Eliminem totes les coses que no siguin paraules, excepte si no es coneix.
        - Comprova posicio per posicio si es la mateixa 
- Hem utilitzat el model resnet101, i hem comprovat com no hi ha gaire diferencia alhora dexecutar poques epoques, pel que ens hem decidit per seguir intentant millorar el model de resnet 50
- Hem  canviat el learning rate, hem pasat de 3e-4 a 0.01, i despres hem canviat el optimitzadpr de adam a sgd per poder fer que el lr  es vagi adaptant al mmodel depenent de com entrena.
- Hem calcula una nova metrica que es la perplexity:
    - En comptes de passar paraules passem numeros
    - menys perplexity millor validacio
    - calcula la entropia cruzada entre les distribucions de probabilitat predites per el model

Coses que hem de fer: 
- La dimensio de la LSTM canviarla --> rudir i augmentar
- Tres raons per la qual la perplexity pot anar augmentant:
    - 1 --> efecte de saturació, es a dir al principi de l'entrenament, el model pot aprendre ràpidament patrons facils aixo fara que la perpllexity disminueixi,
            a mesura que el model va entrenant més, els patrons mes sutils i complexos es tornen mes dificils d'aprendre, el que pot comportar que la perplexity augmenti.
    - 2 --> overfitting, aixo comporta que els de test augmentaran encara que el de train pugui anar disminuint
    - 3 -- variabilitat de les dades, depenent de si es facil predir o no, es comporatara de una manera o de una altre.




