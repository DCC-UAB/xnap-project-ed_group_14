Coses que hem fet:l
- Dividim el train i test en 80% i 20%
- Creem el dataloader a partir de el dataset
- Hem utilizat la loss --> que es la crossentropy
- WandB, que el que fem 8 per el train, 4 que son per veure com anem entrenant i 4 per veure un exemple de validacio per veure si estem fent overfitting o no.
- Per guardar el millor model hem fet un set de validacio, per cada epoch
- Hem creat el test perque no hi havia, el que fem en el test Ã©s anar imatge per imatge predint.
- Metriques:
    - Coefficient de Jaccard:
        - Eliminem totes les coses que no siguin paraules, excepte si no es coneix.
        - Per veure el model fem una divisio entre les paraules que concordden entre totes.
            - Aquesta metrica nomes mira si estan les paraules sense tenir en compte cap ordre.
    - Bleu Score:
        - Eliminem totes les coses que no siguin paraules, excepte si no es coneix.
        - Comprova posicio per posicio si es la mateixa 
- Hem utilitzat el model resnet101, i hem comprovat com no hi ha gaire diferencia alhora dexecutar poques epoques, pel que ens hem decidit per seguir intentant millorar el model de resnet 50
- Hem  canviat el learning rate, hem pasat de 3e-4 a 0.01, i despres hem canviat el optimitzadpr de adam a sgd per poder fer que el lr  es vagi adaptant al mmodel depenent de com entrena.
- Hem calcula una nova metrica que es la perplexity:
    - En comptes de passar paraules passem numeros
    - menys perplexity millor validacio
    - calcula la entropia cruzada entre les distribucions de probabilitat predites per el model

Coses que hem de fer: 
- La dimensio de la LSTM canviarla --> rudir i augmentar



