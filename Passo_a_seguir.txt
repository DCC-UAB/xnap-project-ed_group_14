Coses que hem fet:l
- Dividim el train i test en 80% i 20%
- Creem el dataloader a partir de el dataset
- Hem utilizat la loss --> que es la crossentropy
- WandB, que el que fem 8 per el train, 4 que son per veure com anem entrenant i 4 per veure un exemple de validacio per veure si estem fent overfitting o no.
- Per guardar el millor model hem fet un set de validacio, per cada epoch
- Hem fet 15 epoques i hem vist com de la 1 a la 15 hem passat de:
    - Epoch 1 --> 726 total loss
    - Epoch 15 --> 377 total loss
- Hem creat el test perque no hi havia, el que fem en el test Ã©s anar imatge per imatge predint.
- Metriques:
    - Coefficient de Jaccard:
        - Eliminem totes les coses que no siguin paraules, excepte si no es coneix.
        - Per veure el model fem una divisio entre les paraules que concordden entre totes.
            - Aquesta metrica nomes mira si estan les paraules sense tenir en compte cap ordre.
    - Bleu Score:
        - Eliminem totes les coses que no siguin paraules, excepte si no es coneix.
        - Comprova posicio per posicio si es la mateixa 
    


Coses que hem de fer:
- Podem utilitzar el resnet101 --> tarda mes, te mes profunditat, te mes parametres
- Podem canviar el learning rate per veure si millora o no
- Perpelxity:
    - En comptes de passar paraules passem numeros
    - menys perplexity millor validacio
    - calcula la entropia cruzada entre les distribucions de probabilitat predites per el model
- Canviar el dataset 
- La dimensio de la LSTM canviarla --> rudir i augmentar



